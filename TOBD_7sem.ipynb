{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\224977\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\224977\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\224977\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\224977\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize as w_tok\n",
    "from nltk.metrics import *\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foose',\n",
       " 'wether',\n",
       " 'persian',\n",
       " 'subbed',\n",
       " 'collins',\n",
       " 'family',\n",
       " 'checkoslavakia',\n",
       " 'cold',\n",
       " 'wowwee',\n",
       " 'christians',\n",
       " 'eyebrow',\n",
       " 'thinly',\n",
       " 'addictive',\n",
       " 'focal',\n",
       " 'increased',\n",
       " 'principle',\n",
       " 'ming',\n",
       " 'vij',\n",
       " 'touch',\n",
       " 'plump',\n",
       " 'tori',\n",
       " 'bragging',\n",
       " 'span',\n",
       " 'evie',\n",
       " 'armondo',\n",
       " 'justifiably',\n",
       " 'mrbreakfast',\n",
       " 'zarians',\n",
       " 'breadstick',\n",
       " 'screw',\n",
       " 'claire',\n",
       " 'slathered',\n",
       " 'daily',\n",
       " 'halve',\n",
       " 'sax',\n",
       " 'gâche',\n",
       " 'regarding',\n",
       " 'contribution',\n",
       " 'roquefort',\n",
       " 'tortellini',\n",
       " 'nison',\n",
       " 'diagonally',\n",
       " 'erickson',\n",
       " 'opaque',\n",
       " 'spatula',\n",
       " 'toasst',\n",
       " 'meatloaves',\n",
       " 'backed',\n",
       " 'dunes',\n",
       " 'ww',\n",
       " 'heck',\n",
       " 'hoping',\n",
       " 'bagel',\n",
       " 'overdue',\n",
       " 'roughage',\n",
       " 'souper',\n",
       " 'flew',\n",
       " 'supporting',\n",
       " 'younguns',\n",
       " 'treats',\n",
       " 'stefado',\n",
       " 'fmaily',\n",
       " 'chez',\n",
       " 'cheescake',\n",
       " 'comfort',\n",
       " 'homestead',\n",
       " 'ranch',\n",
       " 'presenting',\n",
       " 'nobu',\n",
       " 'metric',\n",
       " 'tasmanian',\n",
       " 'since',\n",
       " 'circulating',\n",
       " 'overabundance',\n",
       " 'souls',\n",
       " 'parenthesis',\n",
       " 'casse',\n",
       " 'mountains',\n",
       " 'essen',\n",
       " 'when',\n",
       " 'cooling',\n",
       " 'route',\n",
       " 'disregard',\n",
       " 'jalapeños',\n",
       " 'devilishly',\n",
       " 'bethenny',\n",
       " 'barrels',\n",
       " 'caserole',\n",
       " 'stationery',\n",
       " 'stir',\n",
       " 'nutritionist',\n",
       " 'claimed',\n",
       " 'keebler',\n",
       " 'suace',\n",
       " 'housekeeping',\n",
       " 'h',\n",
       " 'energizing',\n",
       " 'bh',\n",
       " 'teachers',\n",
       " 'soprano',\n",
       " 'ahhhing',\n",
       " 'californian',\n",
       " 'perked',\n",
       " 'ealing',\n",
       " 'suffice',\n",
       " 'salvaged',\n",
       " 'leta',\n",
       " 'turner',\n",
       " 'devotee',\n",
       " 'do',\n",
       " 'microbrews',\n",
       " 'looked',\n",
       " 'evaporates',\n",
       " 'pilsbury',\n",
       " 'unsure',\n",
       " 'bery',\n",
       " 'emeril',\n",
       " 'promotion',\n",
       " 'phyllo',\n",
       " 'chow',\n",
       " 'rewarding',\n",
       " 'downunder',\n",
       " 'elbows',\n",
       " 'teriffic',\n",
       " 'niki',\n",
       " 'escondido',\n",
       " 'poppyseed',\n",
       " 'cusick',\n",
       " 'cool',\n",
       " 'laird',\n",
       " 'cake',\n",
       " 'practical',\n",
       " 'based',\n",
       " 'authentic',\n",
       " 'fashion',\n",
       " 'presliced',\n",
       " 'funnel',\n",
       " 'tickled',\n",
       " 'immortalize',\n",
       " 'ad',\n",
       " 'auction',\n",
       " 'inspire',\n",
       " 'borrowed',\n",
       " 'density',\n",
       " 'novice',\n",
       " 'vet',\n",
       " 'berger',\n",
       " 'tribune',\n",
       " 'secondary',\n",
       " 'ck',\n",
       " 'firming',\n",
       " 'cars',\n",
       " 'grandson',\n",
       " 'shirley',\n",
       " 'orecchiette',\n",
       " 'overlooking',\n",
       " 'grapefruits',\n",
       " 'thee',\n",
       " 'elmore',\n",
       " 'nita',\n",
       " 'horns',\n",
       " 'endless',\n",
       " 'picture',\n",
       " 'borrower',\n",
       " 'dialect',\n",
       " 'ufos',\n",
       " 'mentioned',\n",
       " 'effects',\n",
       " 'pleading',\n",
       " 'creatively',\n",
       " 'electric',\n",
       " 'veggie',\n",
       " 'lousiana',\n",
       " 'partners',\n",
       " 'hallmark',\n",
       " 'has',\n",
       " 'course',\n",
       " 'confusing',\n",
       " 'baking',\n",
       " 'parm',\n",
       " 'zwtii',\n",
       " 'baste',\n",
       " 'subtracted',\n",
       " 'rda',\n",
       " 'coup',\n",
       " 'ovarian',\n",
       " 'companions',\n",
       " 'prepare',\n",
       " 'tofu',\n",
       " 'cuba',\n",
       " 'tabbouleh',\n",
       " 'shapter',\n",
       " 'limited',\n",
       " 'eli',\n",
       " 'pansies',\n",
       " 'marzetti',\n",
       " 'beaten',\n",
       " 'don',\n",
       " 'merm',\n",
       " 'speechless',\n",
       " 'couple',\n",
       " 'resturant',\n",
       " 'heatwave',\n",
       " 'possibly',\n",
       " 'calphalon',\n",
       " 'wilfer',\n",
       " 'cambell',\n",
       " 'dgss',\n",
       " 'sherbet',\n",
       " 'reheating',\n",
       " 'requirement',\n",
       " 'riboflavin',\n",
       " 'dulled',\n",
       " 'reccipe',\n",
       " 'bursts',\n",
       " 'throat',\n",
       " 'steaks',\n",
       " 'lake',\n",
       " 'caloric',\n",
       " 'peaple',\n",
       " 'heriteau',\n",
       " 'fagioli',\n",
       " 'garten',\n",
       " 'troup',\n",
       " 'dixon',\n",
       " 'pleas',\n",
       " 'potine',\n",
       " 'tend',\n",
       " 'picnic',\n",
       " 'solely',\n",
       " 'matzoh',\n",
       " 'strangely',\n",
       " 'discriminating',\n",
       " 'springform',\n",
       " 'khar',\n",
       " 'geogia',\n",
       " 'soviet',\n",
       " 'combo',\n",
       " 'literature',\n",
       " 'hashana',\n",
       " 'math',\n",
       " 'vincent',\n",
       " 'pioneers',\n",
       " 'peeling',\n",
       " 'chivo',\n",
       " 'pronto',\n",
       " 'bulk',\n",
       " 'floury',\n",
       " 'golf',\n",
       " 'elephant',\n",
       " 'lightened',\n",
       " 'crunchy',\n",
       " 'deni',\n",
       " 'return',\n",
       " 'premixing',\n",
       " 'csa',\n",
       " 'fishes',\n",
       " 'africa',\n",
       " 'julee',\n",
       " 'slathers',\n",
       " 'pastors',\n",
       " 'cards',\n",
       " 'differnt',\n",
       " 'angola',\n",
       " 'relative',\n",
       " 'attractively',\n",
       " 'descriptive',\n",
       " 'welsh',\n",
       " 'requires',\n",
       " 'piping',\n",
       " 'firemen',\n",
       " 'pati',\n",
       " 'plann',\n",
       " 'simultaneously',\n",
       " 'delivery',\n",
       " 'loma',\n",
       " 'marula',\n",
       " 'flight',\n",
       " 'uncased',\n",
       " 'lowest',\n",
       " 'thickener',\n",
       " 'impression',\n",
       " 'tonight',\n",
       " 'pushed',\n",
       " 'alas',\n",
       " 'leaden',\n",
       " 'flays',\n",
       " 'jeans',\n",
       " 'carnivore',\n",
       " 'plokkfiskur',\n",
       " 'boughten',\n",
       " 'harina',\n",
       " 'tunisian',\n",
       " 'nickle',\n",
       " 'jeffs',\n",
       " 'enjoyed',\n",
       " 'scale',\n",
       " 'stark',\n",
       " 'orig',\n",
       " 'emperors',\n",
       " 'fiji',\n",
       " 'oysters',\n",
       " 'bob',\n",
       " 'cooperative',\n",
       " 'muc',\n",
       " 'latkes',\n",
       " 'daiquiris',\n",
       " 'corn',\n",
       " 'publishing',\n",
       " 'two',\n",
       " 'wellingtons',\n",
       " 'bizzare',\n",
       " 'newest',\n",
       " 'sandwich',\n",
       " 'year',\n",
       " 'crisper',\n",
       " 'hairdresser',\n",
       " 'gramflour',\n",
       " 'hope',\n",
       " 'a',\n",
       " 'colorful',\n",
       " 'appropriate',\n",
       " 'parboiling',\n",
       " 'tagine',\n",
       " 'specials',\n",
       " 'hold',\n",
       " 'tummy',\n",
       " 'stage',\n",
       " 'fourth',\n",
       " 'wendy',\n",
       " 'muffalata',\n",
       " 'indentation',\n",
       " 'spoonfuls',\n",
       " 'elysian',\n",
       " 'concord',\n",
       " 'refig',\n",
       " 'writer',\n",
       " 'ole',\n",
       " 'special',\n",
       " 'games',\n",
       " 'laksa',\n",
       " 'parlour',\n",
       " 'encountered',\n",
       " 'skill',\n",
       " 'mabo',\n",
       " 'lovefeast',\n",
       " 'congress',\n",
       " 'warmed',\n",
       " 'choice',\n",
       " 'grains',\n",
       " 'shelled',\n",
       " 'flare',\n",
       " 'phoran',\n",
       " 'surprised',\n",
       " 'judgement',\n",
       " 'stewed',\n",
       " 'surname',\n",
       " 'oman',\n",
       " 'situated',\n",
       " 'confectioner',\n",
       " 'unprocessed',\n",
       " 'wisconsin',\n",
       " 'resting',\n",
       " 'bins',\n",
       " 'category',\n",
       " 'subscribed',\n",
       " 'folder',\n",
       " 'natural',\n",
       " 'lucks',\n",
       " 'spareribs',\n",
       " 'blackwell',\n",
       " 'peg',\n",
       " 'interchangeable',\n",
       " 'rubbed',\n",
       " 'hay',\n",
       " 'beverly',\n",
       " 'petals',\n",
       " 'extracts',\n",
       " 'progress',\n",
       " 'mind',\n",
       " 'ho',\n",
       " 'submerge',\n",
       " 'tahini',\n",
       " 'where',\n",
       " 'kevin',\n",
       " 'awaiting',\n",
       " 'highy',\n",
       " 'hips',\n",
       " 'delete',\n",
       " 'abide',\n",
       " 'tailgaiting',\n",
       " 'zabar',\n",
       " 'judy',\n",
       " 'ado',\n",
       " 'bryan',\n",
       " 'broadcasting',\n",
       " 'nigiri',\n",
       " 'bushel',\n",
       " 'parties',\n",
       " 'ceramic',\n",
       " 'hummingbirds',\n",
       " 'block',\n",
       " 'loosely',\n",
       " 'slip',\n",
       " 'cookbook',\n",
       " 'respecting',\n",
       " 'typical',\n",
       " 'turkeys',\n",
       " 'guru',\n",
       " 'springfield',\n",
       " 'nerves',\n",
       " 'dead',\n",
       " 'decidely',\n",
       " 'limoncello',\n",
       " 'stale',\n",
       " 'nekkie',\n",
       " 'enough',\n",
       " 'fen',\n",
       " 'inside',\n",
       " 'sofrito',\n",
       " 'harries',\n",
       " 'yukon',\n",
       " 'spoonful',\n",
       " 'picnics',\n",
       " 'bombay',\n",
       " 'riomaggiore',\n",
       " 'every',\n",
       " 'fransisco',\n",
       " 'iraq',\n",
       " 'runza',\n",
       " 'mailing',\n",
       " 'err',\n",
       " 'replied',\n",
       " 'miserable',\n",
       " 'medrich',\n",
       " 'longitudinally',\n",
       " 'adobado',\n",
       " 'olallieberry',\n",
       " 'ringer',\n",
       " 'gnudi',\n",
       " 'wahlberg',\n",
       " 'kimberly',\n",
       " 'spahetti',\n",
       " 'picknics',\n",
       " 'commissary',\n",
       " 'granitas',\n",
       " 'normande',\n",
       " 'elsewhere',\n",
       " 'technology',\n",
       " 'association',\n",
       " 'wish',\n",
       " 'meza',\n",
       " 'soften',\n",
       " 'madhur',\n",
       " 'oval',\n",
       " 'amber',\n",
       " 'think',\n",
       " 'vegans',\n",
       " 'anchovy',\n",
       " 'poaching',\n",
       " 'cham',\n",
       " 'whoever',\n",
       " 'procrastination',\n",
       " 'modify',\n",
       " 'dei',\n",
       " 'provide',\n",
       " 'lilt',\n",
       " 'savannah',\n",
       " 'hpnotiq',\n",
       " 'lebanese',\n",
       " 'samuelsson',\n",
       " 'truns',\n",
       " 'lent',\n",
       " 'softest',\n",
       " 'immigrants',\n",
       " 'ceasar',\n",
       " 'kburie',\n",
       " 'quince',\n",
       " 'valastro',\n",
       " 'oelek',\n",
       " 'nearby',\n",
       " 'preferable',\n",
       " 'mark',\n",
       " 'kick',\n",
       " 'jumped',\n",
       " 'rewriting',\n",
       " 'pack',\n",
       " 'ml',\n",
       " 'discussing',\n",
       " 'eatery',\n",
       " 'western',\n",
       " 'blissfully',\n",
       " 'spectrum',\n",
       " 'minty',\n",
       " 'okras',\n",
       " 'bleu',\n",
       " 'fred',\n",
       " 'cap',\n",
       " 'weightwatchers',\n",
       " 'gospel',\n",
       " 'stuffed',\n",
       " 'brides',\n",
       " 'college',\n",
       " 'service',\n",
       " 'william',\n",
       " 'filing',\n",
       " 'comes',\n",
       " 'sleep',\n",
       " 'later',\n",
       " 'daunting',\n",
       " 'passover',\n",
       " 'centerpiece',\n",
       " 'shaking',\n",
       " 'calcium',\n",
       " 'savers',\n",
       " 'stein',\n",
       " 'calculator',\n",
       " 'montego',\n",
       " 'combine',\n",
       " 'great',\n",
       " 'cling',\n",
       " 'dagoba',\n",
       " 'additives',\n",
       " 'caesar',\n",
       " 'create',\n",
       " 'sauteing',\n",
       " 'tame',\n",
       " 'chevre',\n",
       " 'convenient',\n",
       " 'rutland',\n",
       " 'lid',\n",
       " 'homemaker',\n",
       " 'z',\n",
       " 'snagged',\n",
       " 'dey',\n",
       " 'contributed',\n",
       " 'lindsay',\n",
       " 'settlements',\n",
       " 'sociable',\n",
       " 'ecstasy',\n",
       " 'folacin',\n",
       " 'curies',\n",
       " 'ducks',\n",
       " 'barks',\n",
       " 'bonus',\n",
       " 'throughout',\n",
       " 'cubed',\n",
       " 'relyea',\n",
       " 'definitely',\n",
       " 'screams',\n",
       " 'lining',\n",
       " 'sooo',\n",
       " 'geared',\n",
       " 'preferential',\n",
       " 'qunioa',\n",
       " 'wasn',\n",
       " 'crustacean',\n",
       " 'lasted',\n",
       " 'good',\n",
       " 'stems',\n",
       " 'aired',\n",
       " 'bellies',\n",
       " 'newly',\n",
       " 'kalbi',\n",
       " 'tuning',\n",
       " 'kruger',\n",
       " 'shortcake',\n",
       " 'extensive',\n",
       " 'roladen',\n",
       " 'bruschetta',\n",
       " 'drunken',\n",
       " 'burn',\n",
       " 'yuuuuuuuuummmmm',\n",
       " 'raux',\n",
       " 'rest',\n",
       " 'customization',\n",
       " 'crucial',\n",
       " 'luncheons',\n",
       " 'lou',\n",
       " 'nutritional',\n",
       " 'wound',\n",
       " 'realistically',\n",
       " 'watches',\n",
       " 'comparable',\n",
       " 'drip',\n",
       " 'mesclun',\n",
       " 'panzanella',\n",
       " 'quickie',\n",
       " 'regions',\n",
       " 'stars',\n",
       " 'best',\n",
       " 'réveillon',\n",
       " 'everybody',\n",
       " 'brushing',\n",
       " 'daytime',\n",
       " 'liquids',\n",
       " 'dire',\n",
       " 'nuke',\n",
       " 'satisfied',\n",
       " 'mustards',\n",
       " 'guasacaca',\n",
       " 'neelys',\n",
       " 'of',\n",
       " 'refrigeration',\n",
       " 'adored',\n",
       " 'colleague',\n",
       " 'griddle',\n",
       " 'moment',\n",
       " 'qt',\n",
       " 'amalfi',\n",
       " 'rise',\n",
       " 'canelloni',\n",
       " 'bruce',\n",
       " 'applicable',\n",
       " 'eliminated',\n",
       " 'wishing',\n",
       " 'hein',\n",
       " 'war',\n",
       " 'impresses',\n",
       " 'proportions',\n",
       " 'ginny',\n",
       " 'earthenware',\n",
       " 'pretend',\n",
       " 'pungent',\n",
       " 'recipients',\n",
       " 'smearing',\n",
       " 'entree',\n",
       " 'hbo',\n",
       " 'bacallà',\n",
       " 'lends',\n",
       " 'remodeled',\n",
       " 'nasturtium',\n",
       " 'barberries',\n",
       " 'husbands',\n",
       " 'drinksmixer',\n",
       " 'buttertarts',\n",
       " 'rolls',\n",
       " 'je',\n",
       " 'alchol',\n",
       " 'clifden',\n",
       " 'nuggets',\n",
       " 'staples',\n",
       " 'cullerton',\n",
       " 'shouted',\n",
       " 'skordomakarona',\n",
       " 'creme',\n",
       " 'pear',\n",
       " 'rocky',\n",
       " 'ties',\n",
       " 'steaknshake',\n",
       " 'answer',\n",
       " 'detective',\n",
       " 'tops',\n",
       " 'remaining',\n",
       " 'were',\n",
       " 'tradionally',\n",
       " 'zante',\n",
       " 'equiptment',\n",
       " 'japan',\n",
       " 'overwhelmingly',\n",
       " 'nelda',\n",
       " 'quinto',\n",
       " 'potentially',\n",
       " 'farther',\n",
       " 'diabetic',\n",
       " 'expecting',\n",
       " 'ample',\n",
       " 'vino',\n",
       " 'manna',\n",
       " 'constrained',\n",
       " 'rudolph',\n",
       " 'spoil',\n",
       " 'pleasures',\n",
       " 'mole',\n",
       " 'branch',\n",
       " 'weed',\n",
       " 'mamon',\n",
       " 'johnny',\n",
       " 'pertain',\n",
       " 'tempted',\n",
       " 'mentions',\n",
       " 'haloumi',\n",
       " 'dining',\n",
       " 'exceptions',\n",
       " 'rendition',\n",
       " 'celebrations',\n",
       " 'california',\n",
       " 'easist',\n",
       " 'sprtiz',\n",
       " 'express',\n",
       " 'lukewarm',\n",
       " 'differ',\n",
       " 'colon',\n",
       " 'interchangeably',\n",
       " 'banquet',\n",
       " 'decide',\n",
       " 'build',\n",
       " 'forgotten',\n",
       " 'scarpariello',\n",
       " 'cusp',\n",
       " 'mousse',\n",
       " 'lakes',\n",
       " 'halloumi',\n",
       " 'hanout',\n",
       " 'offering',\n",
       " 'micheff',\n",
       " 'others',\n",
       " 'gay',\n",
       " 'arent',\n",
       " 'segan',\n",
       " 'blackbery',\n",
       " 'posts',\n",
       " 'voisilmäpeliä',\n",
       " 'maryana',\n",
       " 'jenny',\n",
       " 'ernesto',\n",
       " 'alioli',\n",
       " 'biscut',\n",
       " 'slimlines',\n",
       " 'metro',\n",
       " 'pancit',\n",
       " 'demand',\n",
       " 'tastee',\n",
       " 'benn',\n",
       " 'milkshake',\n",
       " 'betty',\n",
       " 'podleski',\n",
       " 'alternatively',\n",
       " 'turns',\n",
       " 'microwave',\n",
       " 'nutritious',\n",
       " 'convuluted',\n",
       " 'houskeeping',\n",
       " 'sustainable',\n",
       " 'crackerjacks',\n",
       " 'accused',\n",
       " 'ovens',\n",
       " 'loosey',\n",
       " 'scotia',\n",
       " 'pucca',\n",
       " 'sweetened',\n",
       " 'accompaniement',\n",
       " 'sweats',\n",
       " 'tag',\n",
       " 'jasmine',\n",
       " 'wih',\n",
       " 'ibs',\n",
       " 'casseroles',\n",
       " 'graham',\n",
       " 'daunted',\n",
       " 'scheib',\n",
       " 'krok',\n",
       " 'rejected',\n",
       " 'biga',\n",
       " 'cared',\n",
       " 'instead',\n",
       " 'issued',\n",
       " 'deer',\n",
       " 'juicing',\n",
       " 'argiolas',\n",
       " 'gifts',\n",
       " 'twinkees',\n",
       " 'coloring',\n",
       " 'ovenproof',\n",
       " 'ending',\n",
       " 'sulfites',\n",
       " 'ferries',\n",
       " 'ya',\n",
       " 'flimsy',\n",
       " 'pairs',\n",
       " 'somthing',\n",
       " 'ulb',\n",
       " 'deleted',\n",
       " 'nervous',\n",
       " 'expansion',\n",
       " 'exhibition',\n",
       " 'translates',\n",
       " 'fest',\n",
       " 'flexible',\n",
       " 'marketplace',\n",
       " 'ginger',\n",
       " 'down',\n",
       " 'find',\n",
       " 'marrakesh',\n",
       " 'porch',\n",
       " 'shiny',\n",
       " 'complexity',\n",
       " 'leavening',\n",
       " 'carrying',\n",
       " 'im',\n",
       " 'nod',\n",
       " 'sichuan',\n",
       " 'demo',\n",
       " 'leaving',\n",
       " 'michigan',\n",
       " 'elbow',\n",
       " 'enquirer',\n",
       " 'imperative',\n",
       " 'sabra',\n",
       " 'rounds',\n",
       " 'helen',\n",
       " 'tones',\n",
       " 'safflower',\n",
       " 'started',\n",
       " 'picking',\n",
       " 'ham',\n",
       " 'tangible',\n",
       " 'confirm',\n",
       " 'chowder',\n",
       " 'fact',\n",
       " 'punky',\n",
       " 'peperoncino',\n",
       " 'never',\n",
       " 'strange',\n",
       " 'scungilli',\n",
       " 'round',\n",
       " 'tends',\n",
       " 'maya',\n",
       " 'sentinel',\n",
       " 'chevy',\n",
       " 'ribbon',\n",
       " 'shooter',\n",
       " 'marsala',\n",
       " 'kid',\n",
       " 'assumed',\n",
       " 'campagne',\n",
       " 'bouquet',\n",
       " 'brats',\n",
       " 'fumes',\n",
       " 'chipotles',\n",
       " 'supercharged',\n",
       " 'reilly',\n",
       " 'ahhhs',\n",
       " 'immigrant',\n",
       " 'party',\n",
       " 'managed',\n",
       " 'curd',\n",
       " 'concerning',\n",
       " 'today',\n",
       " 'whipping',\n",
       " 'stovies',\n",
       " 'appear',\n",
       " 'oxygen',\n",
       " 'thailand',\n",
       " 'bike',\n",
       " 'passport',\n",
       " 'apprxoximately',\n",
       " 'cranberries',\n",
       " 'lessen',\n",
       " 'avacado',\n",
       " 'scrubbed',\n",
       " 'drovers',\n",
       " 'cored',\n",
       " 'chops',\n",
       " 'leaves',\n",
       " 'linguini',\n",
       " 'oooos',\n",
       " 'stimulating',\n",
       " 'caring',\n",
       " 'recipie',\n",
       " 'lesson',\n",
       " 'shooting',\n",
       " 'affordable',\n",
       " 'dfw',\n",
       " 'soba',\n",
       " 'alsatian',\n",
       " 'mississippi',\n",
       " 'condo',\n",
       " 'athens',\n",
       " 'blessed',\n",
       " 'pizzas',\n",
       " 'northern',\n",
       " 'lugging',\n",
       " 'teton',\n",
       " 'maugans',\n",
       " 'folded',\n",
       " 'secrets',\n",
       " 'chiffon',\n",
       " 'grandfather',\n",
       " 'poland',\n",
       " 'macaroon',\n",
       " 'brining',\n",
       " 'stating',\n",
       " 'tableblend',\n",
       " 'dumpling',\n",
       " 'counting',\n",
       " 'personalize',\n",
       " 'freshwater',\n",
       " 'kimball',\n",
       " 'back',\n",
       " 'dawn',\n",
       " 'janet',\n",
       " 'hole',\n",
       " 'shakelike',\n",
       " 'awhile',\n",
       " 'tessie',\n",
       " 'southeast',\n",
       " 'synonymous',\n",
       " 'livers',\n",
       " 'discussed',\n",
       " 'recreating',\n",
       " 'kvass',\n",
       " 'snapper',\n",
       " 'horribly',\n",
       " 'alters',\n",
       " 'dinnertime',\n",
       " 'testing',\n",
       " 'ree',\n",
       " 'bravas',\n",
       " 'ooh',\n",
       " 'confit',\n",
       " 'bluemoon',\n",
       " 'panama',\n",
       " 'shinny',\n",
       " 'chance',\n",
       " 'tradition',\n",
       " 'insists',\n",
       " 'studied',\n",
       " 'sauerkraut',\n",
       " 'smucker',\n",
       " 'hersheys',\n",
       " 'saturated',\n",
       " 'rookie',\n",
       " 'nowhere',\n",
       " 'dominic',\n",
       " 'kerr',\n",
       " 'maruchan',\n",
       " 'economy',\n",
       " 'delaurentis',\n",
       " 'bottling',\n",
       " 'nicaragua',\n",
       " 'caribana',\n",
       " 'opera',\n",
       " 'heidi',\n",
       " 'waa',\n",
       " 'gaming',\n",
       " 'licorice',\n",
       " 'website',\n",
       " 'adaption',\n",
       " 'bill',\n",
       " 'surreal',\n",
       " 'stirring',\n",
       " 'guard',\n",
       " 'negative',\n",
       " 'live',\n",
       " 'settlers',\n",
       " 'gained',\n",
       " 'chicke',\n",
       " 'hefty',\n",
       " 'hues',\n",
       " 'watching',\n",
       " 'cinnamoney',\n",
       " 'semisweet',\n",
       " 'zoe',\n",
       " 'sandra',\n",
       " 'bisque',\n",
       " 'appetit',\n",
       " 'medium',\n",
       " 'richness',\n",
       " 'boiling',\n",
       " 'lees',\n",
       " 'empire',\n",
       " 'internal',\n",
       " 'key',\n",
       " 'wou',\n",
       " 'nutter',\n",
       " 'archives',\n",
       " 'starbucks',\n",
       " 'regard',\n",
       " 'keys',\n",
       " 'chilean',\n",
       " 'populated',\n",
       " 'liquer',\n",
       " 'stephanie',\n",
       " 'buds',\n",
       " 'ncm',\n",
       " 'skip',\n",
       " 'hemisphere',\n",
       " 'comstock',\n",
       " 'exactly',\n",
       " 'muslim',\n",
       " 'ajinomoto',\n",
       " 'starve',\n",
       " 'geordie',\n",
       " 'ohh',\n",
       " 'floddies',\n",
       " 'opor',\n",
       " 'dedicate',\n",
       " 'interview',\n",
       " 'lean',\n",
       " 'specialty',\n",
       " 'parsley',\n",
       " 'hood',\n",
       " 'pogo',\n",
       " 'jesse',\n",
       " 'verrry',\n",
       " 'beehive',\n",
       " 'gump',\n",
       " 'awkward',\n",
       " 'nabnian',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes = pd.read_csv('recipes_sample.csv', delimiter=',').dropna()\n",
    "words = []\n",
    "for description in recipes.description.values:\n",
    "    words += w_tok(description)\n",
    "words2 = [w for w in words if w.isalpha()]\n",
    "f_ex = list(set(words2))\n",
    "f_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расстояние между for и hit : 3\n",
      "Расстояние между : и fat : 3\n",
      "Расстояние между a и has : 2\n",
      "Расстояние между before и one : 4\n",
      "Расстояние между favorite и , : 8\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    w1, w2  = random.sample(words, 2)\n",
    "    distance = edit_distance(w1, w2)\n",
    "    print(f\"Расстояние между {w1} и {w2} : {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'lem', 'lemon', 'leta', 'klemm']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def closest(word, words,k):\n",
    "    descriptions = {w: edit_distance(word, w) for w in words}\n",
    "    return sorted(descriptions, key = descriptions.get )[:k]\n",
    "closest('lemma', words,5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>foose</th>\n",
       "      <td>foos</td>\n",
       "      <td>foose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wether</th>\n",
       "      <td>wether</td>\n",
       "      <td>wether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persian</th>\n",
       "      <td>persian</td>\n",
       "      <td>persian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subbed</th>\n",
       "      <td>sub</td>\n",
       "      <td>subbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collins</th>\n",
       "      <td>collin</td>\n",
       "      <td>collins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>famili</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checkoslavakia</th>\n",
       "      <td>checkoslavakia</td>\n",
       "      <td>checkoslavakia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>cold</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wowwee</th>\n",
       "      <td>wowwe</td>\n",
       "      <td>wowwee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christians</th>\n",
       "      <td>christian</td>\n",
       "      <td>christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyebrow</th>\n",
       "      <td>eyebrow</td>\n",
       "      <td>eyebrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thinly</th>\n",
       "      <td>thin</td>\n",
       "      <td>thinly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addictive</th>\n",
       "      <td>addict</td>\n",
       "      <td>addictive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>focal</th>\n",
       "      <td>focal</td>\n",
       "      <td>focal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>increased</th>\n",
       "      <td>increas</td>\n",
       "      <td>increased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  stemmed_word normalized_word\n",
       "word                                          \n",
       "foose                     foos           foose\n",
       "wether                  wether          wether\n",
       "persian                persian         persian\n",
       "subbed                     sub          subbed\n",
       "collins                 collin         collins\n",
       "family                  famili          family\n",
       "checkoslavakia  checkoslavakia  checkoslavakia\n",
       "cold                      cold            cold\n",
       "wowwee                   wowwe          wowwee\n",
       "christians           christian       christian\n",
       "eyebrow                eyebrow         eyebrow\n",
       "thinly                    thin          thinly\n",
       "addictive               addict       addictive\n",
       "focal                    focal           focal\n",
       "increased              increas       increased"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snb_stemmer_eng = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "dic = {'word': f_ex, 'stemmed_word': [snb_stemmer_eng.stem(word) for word in f_ex],\n",
    "                   'normalized_word': [lemmatizer.lemmatize(word) for word in f_ex ]}\n",
    "dt = pd.DataFrame(dic).set_index('word')\n",
    "dt[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До удаления стоп-слов:\n",
      "\n",
      "[('the', 17817), ('a', 15494), ('and', 13464), ('i', 12317), ('this', 12003), ('it', 10407), ('to', 10403), ('is', 9106), ('of', 8061), ('for', 6986)]\n",
      "\n",
      "После: \n",
      "\n",
      "[('recipe', 6656), ('make', 2789), ('time', 2379), ('use', 2052), ('great', 2027), ('easy', 1853), ('like', 1812), ('one', 1758), ('made', 1679), ('good', 1671)]\n",
      "\n",
      "Доля стоп-слов от общего кол-ва: \n",
      "\n",
      "47.401612962021844\n"
     ]
    }
   ],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "top_before = FreqDist(words2).most_common(10) \n",
    "\n",
    "lst_no_stop = [w for w in words2 if w.lower() not in stops ] \n",
    "top_after = FreqDist(lst_no_stop).most_common(10)\n",
    "\n",
    "stop_procent = (len([w for w in words2 if w.lower() in stops])/len(words2))*100\n",
    "\n",
    "print('До удаления стоп-слов:' ,top_before ,'После: ', top_after, 'Доля стоп-слов от общего кол-ва: ', stop_procent, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nazvanie рецепта : triple sec salmon\n",
      "\n",
      "Векторное представление :\n",
      " [0.         0.         0.         0.         0.19595145 0.19595145\n",
      " 0.13123097 0.         0.19595145 0.         0.         0.\n",
      " 0.         0.         0.31618479 0.         0.         0.\n",
      " 0.         0.19595145 0.         0.3919029  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.19595145 0.         0.         0.\n",
      " 0.         0.19595145 0.         0.         0.         0.\n",
      " 0.         0.19595145 0.         0.         0.         0.\n",
      " 0.         0.         0.13123097 0.         0.         0.\n",
      " 0.         0.         0.         0.19595145 0.19595145 0.\n",
      " 0.         0.19595145 0.19595145 0.         0.         0.\n",
      " 0.         0.         0.         0.11039563 0.         0.\n",
      " 0.         0.19595145 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.18674383 0.         0.19595145 0.         0.         0.\n",
      " 0.11039563 0.         0.         0.         0.19595145 0.19595145\n",
      " 0.         0.         0.         0.19595145 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.19595145 0.        ]\n",
      "\n",
      "Nazvanie рецепта : cajun string   green beans\n",
      "\n",
      "Векторное представление :\n",
      " [0.         0.         0.2761163  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.44553779 0.         0.2761163  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.2227689\n",
      " 0.2761163  0.         0.         0.         0.2761163  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15555911 0.\n",
      " 0.         0.2761163  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.15555911 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.1315709  0.         0.         0.         0.         0.2761163\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2761163  0.         0.2761163  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.2761163  0.\n",
      " 0.         0.         0.        ]\n",
      "\n",
      "Nazvanie рецепта : warm bacon dressing for spinach salad\n",
      "\n",
      "Векторное представление :\n",
      " [0.         0.         0.         0.16180726 0.         0.\n",
      " 0.         0.         0.         0.         0.16180726 0.16180726\n",
      " 0.         0.         0.         0.         0.16180726 0.\n",
      " 0.         0.         0.16180726 0.         0.16180726 0.\n",
      " 0.         0.         0.         0.         0.16180726 0.16180726\n",
      " 0.         0.16180726 0.         0.13054508 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.16180726 0.16180726 0.         0.\n",
      " 0.26109015 0.         0.21672841 0.         0.18231877 0.\n",
      " 0.16180726 0.         0.16180726 0.         0.         0.\n",
      " 0.16180726 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.16180726 0.16180726\n",
      " 0.16180726 0.         0.13054508 0.         0.         0.\n",
      " 0.         0.16180726 0.16180726 0.         0.         0.\n",
      " 0.15420405 0.         0.         0.16180726 0.16180726 0.\n",
      " 0.09115939 0.16180726 0.         0.16180726 0.         0.\n",
      " 0.         0.         0.         0.         0.16180726 0.16180726\n",
      " 0.16180726 0.16180726 0.16180726 0.         0.         0.16180726\n",
      " 0.16180726 0.         0.        ]\n",
      "\n",
      "Nazvanie рецепта : pumpkin pie a la easy\n",
      "\n",
      "Векторное представление :\n",
      " [0.16388539 0.16388539 0.         0.         0.         0.\n",
      " 0.10975596 0.16388539 0.         0.1322217  0.         0.\n",
      " 0.16388539 0.16388539 0.1322217  0.         0.         0.16388539\n",
      " 0.16388539 0.         0.         0.         0.         0.\n",
      " 0.1322217  0.         0.         0.16388539 0.         0.\n",
      " 0.16388539 0.         0.         0.2644434  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.16388539 0.16388539\n",
      " 0.1322217  0.         0.21951191 0.         0.09233017 0.\n",
      " 0.         0.         0.         0.         0.         0.1322217\n",
      " 0.         0.         0.         0.16388539 0.16388539 0.16388539\n",
      " 0.32777078 0.16388539 0.16388539 0.09233017 0.         0.\n",
      " 0.         0.         0.         0.         0.16388539 0.16388539\n",
      " 0.         0.         0.         0.16388539 0.16388539 0.\n",
      " 0.07809227 0.16388539 0.         0.         0.         0.\n",
      " 0.18466034 0.         0.         0.         0.         0.\n",
      " 0.         0.16388539 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.16388539]\n",
      "\n",
      "Nazvanie рецепта : irregular green bean casserole\n",
      "\n",
      "Векторное представление :\n",
      " [0.         0.         0.         0.         0.         0.\n",
      " 0.14262784 0.         0.         0.17182207 0.         0.\n",
      " 0.         0.         0.         0.21296903 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.21296903\n",
      " 0.         0.21296903 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.21296903 0.17182207\n",
      " 0.         0.         0.21296903 0.21296903 0.         0.21296903\n",
      " 0.21296903 0.         0.         0.         0.         0.\n",
      " 0.         0.21296903 0.         0.21296903 0.11998303 0.21296903\n",
      " 0.         0.         0.         0.         0.         0.17182207\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.11998303 0.         0.\n",
      " 0.         0.         0.17182207 0.21296903 0.         0.\n",
      " 0.21296903 0.         0.         0.         0.         0.21296903\n",
      " 0.30444265 0.         0.         0.         0.         0.\n",
      " 0.11998303 0.         0.21296903 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.21296903 0.         0.\n",
      " 0.         0.         0.        ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_5 = recipes.sample(n=5)\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "corpus = random_5.description.values\n",
    "corpus_tv = tv.fit_transform(corpus)\n",
    "\n",
    "for i, recipe in enumerate(random_5.name):\n",
    "    print(f\"Nazvanie рецепта : {recipe}\\n\")\n",
    "    print(f'Векторное представление :\\n {corpus_tv.toarray()[i]}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triple sec salmon</th>\n",
       "      <th>cajun string   green beans</th>\n",
       "      <th>warm bacon dressing for spinach salad</th>\n",
       "      <th>pumpkin pie a la easy</th>\n",
       "      <th>irregular green bean casserole</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>triple sec salmon</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958257</td>\n",
       "      <td>0.932698</td>\n",
       "      <td>0.869822</td>\n",
       "      <td>0.897939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cajun string   green beans</th>\n",
       "      <td>0.958257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.951350</td>\n",
       "      <td>0.902090</td>\n",
       "      <td>0.884339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warm bacon dressing for spinach salad</th>\n",
       "      <td>0.932698</td>\n",
       "      <td>0.951350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.837673</td>\n",
       "      <td>0.897810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pumpkin pie a la easy</th>\n",
       "      <td>0.869822</td>\n",
       "      <td>0.902090</td>\n",
       "      <td>0.837673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.870822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irregular green bean casserole</th>\n",
       "      <td>0.897939</td>\n",
       "      <td>0.884339</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.870822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       triple sec salmon  \\\n",
       "name                                                       \n",
       "triple sec salmon                               0.000000   \n",
       "cajun string   green beans                      0.958257   \n",
       "warm bacon dressing for spinach salad           0.932698   \n",
       "pumpkin pie a la easy                           0.869822   \n",
       "irregular green bean casserole                  0.897939   \n",
       "\n",
       "                                       cajun string   green beans  \\\n",
       "name                                                                \n",
       "triple sec salmon                                        0.958257   \n",
       "cajun string   green beans                               0.000000   \n",
       "warm bacon dressing for spinach salad                    0.951350   \n",
       "pumpkin pie a la easy                                    0.902090   \n",
       "irregular green bean casserole                           0.884339   \n",
       "\n",
       "                                       warm bacon dressing for spinach salad  \\\n",
       "name                                                                           \n",
       "triple sec salmon                                                   0.932698   \n",
       "cajun string   green beans                                          0.951350   \n",
       "warm bacon dressing for spinach salad                               0.000000   \n",
       "pumpkin pie a la easy                                               0.837673   \n",
       "irregular green bean casserole                                      0.897810   \n",
       "\n",
       "                                       pumpkin pie a la easy  \\\n",
       "name                                                           \n",
       "triple sec salmon                                   0.869822   \n",
       "cajun string   green beans                          0.902090   \n",
       "warm bacon dressing for spinach salad               0.837673   \n",
       "pumpkin pie a la easy                               0.000000   \n",
       "irregular green bean casserole                      0.870822   \n",
       "\n",
       "                                       irregular green bean casserole  \n",
       "name                                                                   \n",
       "triple sec salmon                                            0.897939  \n",
       "cajun string   green beans                                   0.884339  \n",
       "warm bacon dressing for spinach salad                        0.897810  \n",
       "pumpkin pie a la easy                                        0.870822  \n",
       "irregular green bean casserole                               0.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools as itl\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "corpus2 = corpus_tv.toarray()\n",
    "dt_empty = pd.DataFrame(index=random_5.name)\n",
    "\n",
    "glued_corp = list(itl.chain.from_iterable([corpus2]) )  # corpus2 - список списков\n",
    "products = list(itl.product(glued_corp, repeat=2)) # Создаем пары векторов рецептов\n",
    "\n",
    "cos_distance = list(itl.starmap(cosine, products))\n",
    "\n",
    "end = 0\n",
    "for name_col in random_5.name:\n",
    "    dt_empty[name_col] = cos_distance[end:end+5]\n",
    "    end+=5\n",
    "\n",
    "dt_empty \n",
    "\n",
    "# Чем больше cos, и  \n",
    "# меньше косинусное расстояние (1-cos), тем более схожи векторы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем меньше косинусное расстояние между двумя векторами(рецептами), тем более похожими они являются. Если не брать в расчет рецепты с растоянием 0, самыми похожими друг на друга рецептами являются \"warm bacon dressing for spinach salad\" и \"pumpkin pie a la easy\" с растоянием - 0.837673\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
